import puppeteer from 'puppeteer';
import Parser from 'rss-parser';

export interface ScrapedBenefit {
  title: string;
  content: string;
  url: string;
  agency: string;
  publishedDate: string;
  source: string;
}

// RSS íŒŒì„œ ì´ˆê¸°í™”
const parser = new Parser();

// ì •ë¶€ ê¸°ê´€ RSS í”¼ë“œ ëª©ë¡
const RSS_FEEDS = [
  {
    url: 'https://www.moel.go.kr/rss/all.xml',
    agency: 'ê³ ìš©ë…¸ë™ë¶€',
    name: 'moel'
  },
  {
    url: 'https://www.kosaf.go.kr/ko/common/board/rss.do?boardId=BRD_000000000000070',
    agency: 'í•œêµ­ì¥í•™ì¬ë‹¨',
    name: 'kosaf'
  },
  {
    url: 'https://www.mafra.go.kr/rss/policyNews.xml',
    agency: 'ë†ë¦¼ì¶•ì‚°ì‹í’ˆë¶€', 
    name: 'mafra'
  }
];

// í¬ë¡¤ë§ ëŒ€ìƒ ì‚¬ì´íŠ¸
const SCRAPING_TARGETS = [
  {
    url: 'https://www.gov.kr/portal/ntnadmNews/1674758',
    agency: 'ì •ë¶€24',
    selector: '.board_list .list_item',
    name: 'gov'
  }
];

/**
 * RSS í”¼ë“œì—ì„œ ìµœì‹  ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
 */
export async function scrapeRSSFeeds(): Promise<ScrapedBenefit[]> {
  const results: ScrapedBenefit[] = [];
  
  for (const feed of RSS_FEEDS) {
    try {
      console.log(`RSS í”¼ë“œ ìˆ˜ì§‘ ì¤‘: ${feed.agency}`);
      const parsed = await parser.parseURL(feed.url);
      
      // ìµœê·¼ 7ì¼ê°„ì˜ í•­ëª©ë§Œ ê°€ì ¸ì˜¤ê¸°
      const weekAgo = new Date();
      weekAgo.setDate(weekAgo.getDate() - 7);
      
      for (const item of parsed.items.slice(0, 10)) { // ìµœëŒ€ 10ê°œ
        const publishedDate = item.pubDate ? new Date(item.pubDate) : new Date();
        
        if (publishedDate >= weekAgo) {
          results.push({
            title: item.title || '',
            content: item.contentSnippet || item.content || '',
            url: item.link || '',
            agency: feed.agency,
            publishedDate: publishedDate.toISOString(),
            source: `rss_${feed.name}`
          });
        }
      }
    } catch (error) {
      console.error(`RSS í”¼ë“œ ì˜¤ë¥˜ (${feed.agency}):`, error);
    }
  }
  
  return results;
}

/**
 * ì›¹ í¬ë¡¤ë§ìœ¼ë¡œ ìµœì‹  ê³µì§€ì‚¬í•­ ê°€ì ¸ì˜¤ê¸°
 */
export async function scrapeWebsites(): Promise<ScrapedBenefit[]> {
  const results: ScrapedBenefit[] = [];
  let browser;
  
  try {
    browser = await puppeteer.launch({ 
      headless: true,
      args: ['--no-sandbox', '--disable-setuid-sandbox']
    });
    
    for (const target of SCRAPING_TARGETS) {
      try {
        console.log(`ì›¹ í¬ë¡¤ë§ ì¤‘: ${target.agency}`);
        const page = await browser.newPage();
        await page.goto(target.url, { waitUntil: 'networkidle2' });
        
        // ê³µì§€ì‚¬í•­ ëª©ë¡ ì¶”ì¶œ
        const items = await page.evaluate((selector) => {
          const elements = document.querySelectorAll(selector);
          return Array.from(elements).slice(0, 10).map(el => {
            const titleEl = el.querySelector('a') || el.querySelector('.title');
            const dateEl = el.querySelector('.date') || el.querySelector('.reg_date');
            
            return {
              title: titleEl?.textContent?.trim() || '',
              url: titleEl?.getAttribute('href') || '',
              date: dateEl?.textContent?.trim() || ''
            };
          });
        }, target.selector);
        
        // ê° í•­ëª©ì˜ ìƒì„¸ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        for (const item of items) {
          if (item.title && item.url) {
            try {
              const detailPage = await browser.newPage();
              const fullUrl = item.url.startsWith('http') ? item.url : `${new URL(target.url).origin}${item.url}`;
              await detailPage.goto(fullUrl, { waitUntil: 'networkidle2' });
              
              const content = await detailPage.evaluate(() => {
                const contentEl = document.querySelector('.view_content') || 
                                document.querySelector('.content') ||
                                document.querySelector('.board_view');
                return contentEl?.textContent?.trim() || '';
              });
              
              results.push({
                title: item.title,
                content: content.substring(0, 1000), // ì²« 1000ìë§Œ
                url: fullUrl,
                agency: target.agency,
                publishedDate: new Date().toISOString(),
                source: `web_${target.name}`
              });
              
              await detailPage.close();
            } catch (detailError) {
              console.error('ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§ ì˜¤ë¥˜:', detailError);
            }
          }
        }
        
        await page.close();
      } catch (error) {
        console.error(`ì›¹ í¬ë¡¤ë§ ì˜¤ë¥˜ (${target.agency}):`, error);
      }
    }
  } catch (error) {
    console.error('ë¸Œë¼ìš°ì € ì´ˆê¸°í™” ì˜¤ë¥˜:', error);
  } finally {
    if (browser) {
      await browser.close();
    }
  }
  
  return results;
}

/**
 * ëª¨ë“  ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
 */
export async function scrapeAllSources(): Promise<ScrapedBenefit[]> {
  console.log('ğŸ“¡ ì‹¤ì‹œê°„ í˜œíƒ ì—…ë°ì´íŠ¸ ì‹œì‘...');
  
  const [rssResults, webResults] = await Promise.all([
    scrapeRSSFeeds(),
    scrapeWebsites()
  ]);
  
  const allResults = [...rssResults, ...webResults];
  console.log(`ğŸ“Š ì´ ${allResults.length}ê°œì˜ ìƒˆë¡œìš´ í•­ëª©ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.`);
  
  return allResults;
}